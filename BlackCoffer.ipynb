{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "aHSOJ0FwJ8C0"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZcHPBVmhKvxY"
   },
   "outputs": [],
   "source": [
    "import urllib.request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j5nqxoqHNrzE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dw9Uq1WYhWSS",
    "outputId": "e60d31ae-7494-4349-a1fa-8b0190f426bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import nltk\n",
    " nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "P_qlWlfhM-qs"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KMEJ9TKzYq-x"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "BsKtXN53L7g-"
   },
   "outputs": [],
   "source": [
    "file = pd.read_excel('Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aurxJfHN934"
   },
   "outputs": [],
   "source": [
    "#extracting content and titles from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "4m6aGK_QEsfV"
   },
   "outputs": [],
   "source": [
    "def extract_title_content(df):\n",
    "    ''' Extracting title and content from urls'''\n",
    "    from bs4 import BeautifulSoup\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "      }\n",
    "\n",
    "    URL = df.URL\n",
    "    r = requests.get(URL, headers= headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    text = soup.find_all(text=True)\n",
    "    #set([t.parent.name for t in text])\n",
    "\n",
    "    blacklist = [\n",
    "        '[document]','noscript','header','html',\n",
    "        'meta','head', 'input','script','a',\n",
    "     'article','aside','body','button','div',\n",
    "     'figcaption','footer','form', 'h1',\n",
    "     'head', 'header', 'html', 'li',\n",
    "     'link', 'meta',  'pre', 'script',\n",
    "     'span', 'strong', 'style', 'time', 'ul']\n",
    "    for t in text:\n",
    "        if t.parent.name not in blacklist:\n",
    "            if t.parent.name == 'title':\n",
    "                title=t\n",
    "            else:\n",
    "                content = t\n",
    "\n",
    "    df['Title'] = title\n",
    "    df['content'] =content\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "cYdnD5IkFnJ0"
   },
   "outputs": [],
   "source": [
    "file=file.apply(extract_title_content, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BGXldptVYpib",
    "outputId": "73c1e539-58a8-458a-fa13-11a158cf5fee"
   },
   "outputs": [],
   "source": [
    "# saving file with content and title\n",
    "file.to_csv('file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ACCWRYUxhq5A"
   },
   "outputs": [],
   "source": [
    "# creating list of Stopwords\n",
    "with open (\"StopWords_Generic.txt\", 'r') as f:\n",
    "    stop = f.readlines()\n",
    "    stopwords =[]\n",
    "    for word in stop:\n",
    "        stopwords.append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vp1g9L5JgjFb"
   },
   "outputs": [],
   "source": [
    "# loading saved file in earlier steps\n",
    "file=pd.read_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Postive Negative words Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pd.read_csv('MasterDictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive= dic.Word[dic.Positive!=0].to_list()\n",
    "negative = dic.Word[dic.Negative!=0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dic=dict()\n",
    "new_dic['Positive'] = [word for word in positive if word not in stopwords]\n",
    "new_dic['Negative'] =[word for word in negative if word not in stopwords ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "vnP-jmLnfDTw"
   },
   "outputs": [],
   "source": [
    "def calculating_scores(row):\n",
    "    '''Analysis of text'''\n",
    "    tokens = word_tokenize(row.content)\n",
    "    total_unclean_words = len(tokens)\n",
    "    tokens= [x.upper() for x in tokens]\n",
    "    #removing punctuatuion\n",
    "    tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens]\n",
    "    pos=0; neg=0 ; ch =0\n",
    "    for token in tokens:\n",
    "        ch += len(token)\n",
    "        if token in new_dic['Positive']:\n",
    "            pos +=1\n",
    "        elif  token in new_dic['Negative']:\n",
    "            neg -=1  \n",
    "    neg = neg * (-1)\n",
    "    polarity = (pos-neg)/ ((pos + neg) + 0.000001) \n",
    "    cont = row.content\n",
    "    word = cont.split()\n",
    "    cont_clean=[token for token in tokens if token not in stopwords]\n",
    "    tot_clean_words = len(cont_clean)\n",
    "    \n",
    "    sentence = sent_tokenize(row.content)\n",
    "    tot_sent = len(sentence)\n",
    "    av_sent_len = tot_clean_words/(tot_sent + 0.000001)\n",
    "    \n",
    "    count_complexWord, avg_syllablePerWord = count_complex(row.content)\n",
    "    perc_complex = count_complexWord / (tot_clean_words+ 0.000001)\n",
    "    fogIndex = 0.4 * (av_sent_len + perc_complex)\n",
    "    \n",
    "    subjectivity = (pos + neg)/ (tot_clean_words + 0.000001)\n",
    "    \n",
    "    avg_wordPerSent = total_unclean_words/(tot_sent + 0.000001)\n",
    "    \n",
    "    av_word_length = ch/(total_unclean_words+ 0.000001)\n",
    "    count_perspronoun = count_pronoun(row.content)\n",
    "    \n",
    "    \n",
    "    row['POSITIVE SCORE'] = pos\n",
    "    row['NEGATIVE SCORE'] =  neg\n",
    "    row['POLARITY SCORE'] =  polarity\n",
    "    row['SUBJECTIVITY SCORE'] =  subjectivity\n",
    "    row['AVG SENTENCE LENGTH'] =  av_sent_len\n",
    "    row['PERCENTAGE OF COMPLEX WORDS'] =  perc_complex\n",
    "    row['FOG INDEX'] =  fogIndex\n",
    "    row['AVG NUMBER OF WORDS PER SENTENCE'] =  avg_wordPerSent\n",
    "    row['COMPLEX WORD COUNT'] =  count_complexWord\n",
    "    row['WORD COUNT'] =  tot_clean_words\n",
    "    row['SYLLABLE PER WORD'] =  avg_syllablePerWord\n",
    "    row['PERSONAL PRONOUNS'] =  count_perspronoun\n",
    "    row['AVG WORD LENGTH'] =  av_word_length\n",
    "    \n",
    "    return row     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_complex(text):\n",
    "    '''counting syllables and complex words'''\n",
    "    complx= []\n",
    "    vowel_l = []\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens= [x.lower() for x in tokens]\n",
    "    for token in tokens:\n",
    "        vowel = len(re.findall(\"e|a|i|o|u\", token))-len(re.findall(\"\\w+ed|s$\", token))\n",
    "        vowel_l.append(vowel)\n",
    "        if vowel > 2 :\n",
    "            complx.append(token)\n",
    "#     print(tokens)\n",
    "#     print(vowel,complx)        \n",
    "    return len(complx) , np.mean(vowel_l)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pronoun(text):\n",
    "    '''counting personal pronoun (excluding country US)'''\n",
    "    tot = 0\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronoun = pronounRegex.findall(text)\n",
    "    total = len(pronoun)\n",
    "      \n",
    "    return total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>How is Login Logout Time Tracking for Employee...</td>\n",
       "      <td>With the use of AI and Deep Learning technolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>How does AI help to monitor Retail Shelf watch...</td>\n",
       "      <td>By this system, if it is implemented in a supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>AI and its impact on the Fashion Industry - Bl...</td>\n",
       "      <td>It’s too early to tell how these AI applicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>How do deep learning models predict old and ne...</td>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>How artificial intelligence can boost your pro...</td>\n",
       "      <td>So, what we have understood is AI has penetrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0     1.0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1     2.0  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2     3.0  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3     4.0  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4     5.0  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How is Login Logout Time Tracking for Employee...   \n",
       "1  How does AI help to monitor Retail Shelf watch...   \n",
       "2  AI and its impact on the Fashion Industry - Bl...   \n",
       "3  How do deep learning models predict old and ne...   \n",
       "4  How artificial intelligence can boost your pro...   \n",
       "\n",
       "                                             content  \n",
       "0  With the use of AI and Deep Learning technolog...  \n",
       "1  By this system, if it is implemented in a supe...  \n",
       "2  It’s too early to tell how these AI applicatio...  \n",
       "3  Understanding exactly how data is ingested, an...  \n",
       "4  So, what we have understood is AI has penetrat...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = file.apply(calculating_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>content</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>How is Login Logout Time Tracking for Employee...</td>\n",
       "      <td>With the use of AI and Deep Learning technolog...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.999950</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>20.079980</td>\n",
       "      <td>49.999950</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>How does AI help to monitor Retail Shelf watch...</td>\n",
       "      <td>By this system, if it is implemented in a supe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>64.499968</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>25.837196</td>\n",
       "      <td>64.499968</td>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>1.341085</td>\n",
       "      <td>2</td>\n",
       "      <td>4.062015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>AI and its impact on the Fashion Industry - Bl...</td>\n",
       "      <td>It’s too early to tell how these AI applicatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>29.999985</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>12.073327</td>\n",
       "      <td>29.999985</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>4.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>How do deep learning models predict old and ne...</td>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>32.928569</td>\n",
       "      <td>0.245119</td>\n",
       "      <td>13.269475</td>\n",
       "      <td>32.928569</td>\n",
       "      <td>113</td>\n",
       "      <td>461</td>\n",
       "      <td>1.713666</td>\n",
       "      <td>1</td>\n",
       "      <td>4.867679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>How artificial intelligence can boost your pro...</td>\n",
       "      <td>So, what we have understood is AI has penetrat...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>15.666661</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>6.343260</td>\n",
       "      <td>15.666661</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>1.553191</td>\n",
       "      <td>2</td>\n",
       "      <td>4.021277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  \\\n",
       "0     1.0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1     2.0  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2     3.0  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3     4.0  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4     5.0  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  How is Login Logout Time Tracking for Employee...   \n",
       "1  How does AI help to monitor Retail Shelf watch...   \n",
       "2  AI and its impact on the Fashion Industry - Bl...   \n",
       "3  How do deep learning models predict old and ne...   \n",
       "4  How artificial intelligence can boost your pro...   \n",
       "\n",
       "                                             content  POSITIVE SCORE  \\\n",
       "0  With the use of AI and Deep Learning technolog...               0   \n",
       "1  By this system, if it is implemented in a supe...               1   \n",
       "2  It’s too early to tell how these AI applicatio...               1   \n",
       "3  Understanding exactly how data is ingested, an...               5   \n",
       "4  So, what we have understood is AI has penetrat...               2   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0               0        0.000000            0.000000            49.999950   \n",
       "1               0        0.999999            0.007752            64.499968   \n",
       "2               0        0.999999            0.016667            29.999985   \n",
       "3               1        0.666667            0.013015            32.928569   \n",
       "4               1        0.333333            0.063830            15.666661   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                     0.200000  20.079980                         49.999950   \n",
       "1                     0.093023  25.837196                         64.499968   \n",
       "2                     0.183333  12.073327                         29.999985   \n",
       "3                     0.245119  13.269475                         32.928569   \n",
       "4                     0.191489   6.343260                         15.666661   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                  10          50           1.780000                  1   \n",
       "1                  12         129           1.341085                  2   \n",
       "2                  11          60           1.666667                  0   \n",
       "3                 113         461           1.713666                  1   \n",
       "4                   9          47           1.553191                  2   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         4.920000  \n",
       "1         4.062015  \n",
       "2         4.566667  \n",
       "3         4.867679  \n",
       "4         4.021277  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv('output_Rashi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BlackCoffer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
